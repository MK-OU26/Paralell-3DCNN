{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0624832b-b7ba-4f53-9c12-9de7c42b2d2d",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# 1. データの読み込みと前処理"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ded88359-aa45-4c7c-ac93-f4269f4bbb7c",
   "metadata": {},
   "source": [
    "*必要なライブラリのインポート*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fca24c9d-063a-4c3a-a38f-cbf1f1877fff",
   "metadata": {},
   "outputs": [],
   "source": [
    "import av\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "\n",
    "from torchvision import transforms\n",
    "from torchvision.datasets import UCF101\n",
    "from torchmetrics import Accuracy\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bee627d-185c-41fb-b757-411c2a9d1c5a",
   "metadata": {},
   "source": [
    "ダウンロード先のディレクトリを設定"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ba531bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ダウンロード先のディレクトリ\n",
    "root = 'C:\\\\Users\\\\Username\\\\Documents\\\\Python Scripts\\\\forUCF101\\\\UCF101_data\\\\UCF101\\\\UCF-101'\n",
    "root_label = 'C:\\\\Users\\\\Username\\\\Documents\\\\Python Scripts\\\\forUCF101\\\\UCF101_data\\\\UCF101\\\\UCF101TrainTestSplits-RecognitionTask\\\\ucfTrainTestlist'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06f56716-37c6-44c5-98e5-348776ff3d13",
   "metadata": {},
   "source": [
    "変数の設定"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1989c440",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1動画における時間の長さ\n",
    "frames_per_clip = 75\n",
    "# 動画間の長さ(＝使用する動画の量が決まる)\n",
    "step_between_clips = 100\n",
    "# バッチサイズ\n",
    "batch_size = 1\n",
    "# 動画のフレームサイズ\n",
    "height = 255\n",
    "width = 255\n",
    "# ラベル数\n",
    "label_num = 101\n",
    "# 畳み込み層第1層のチャンネル数\n",
    "num_channel = 32\n",
    "# 畳み込み層第1層のフィルタサイズ\n",
    "filter_size_conv1 = 11\n",
    "# 訓練(学習)を繰り返す、エポック数\n",
    "epoch_num = 5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83c9cd76-c1e5-4b17-8c26-1ca47f4f8ea1",
   "metadata": {},
   "source": [
    "トランスフォーマーオブジェクトを生成\n",
    "<br>Define the typical preprocessing transforms to be used for training a neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43dea15a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1動画のフレームが「frames_per_clip」より少ない場合、１フレーム目に巻き戻すための関数\n",
    "class PadFrames:\n",
    "    def __init__(self, frames_per_clip):\n",
    "        self.frames_per_clip = frames_per_clip\n",
    "\n",
    "    def __call__(self, video):\n",
    "        num_frames = video.shape[0]\n",
    "        if num_frames < self.frames_per_clip:\n",
    "            repeat_frames = self.frames_per_clip - num_frames\n",
    "            repeated = video[0].unsqueeze(0).repeat(repeat_frames, 1, 1, 1)\n",
    "            video = torch.cat([video, repeated], dim=0)\n",
    "        return video\n",
    "\n",
    "\n",
    "# 訓練データの編集\n",
    "transform_train = transforms.Compose([\n",
    "                  # 上記の関数を使用\n",
    "                  PadFrames(frames_per_clip=frames_per_clip),\n",
    "                  # scale in [0, 1] of type float\n",
    "                  transforms.Lambda(lambda x: x / 255.0),\n",
    "                  # reshape into (THWC→TCHW) for easier convolutions\n",
    "                  transforms.Lambda(lambda x: x.permute(0, 3, 1, 2)),\n",
    "                  transforms.RandomGrayscale(p=0.3),\n",
    "                  # reshape into (TCHW→CTHW) for easier convolutions\n",
    "                  transforms.Lambda(lambda x: x.permute(1, 0, 2, 3)),\n",
    "    \n",
    "                  # rescale to the most common size\n",
    "                  # ランダムに切り取りを行う\n",
    "                  #transforms.RandomCrop((height,width), padding_mode='edge'),\n",
    "                  # 中心だけを切り取るなら↓\n",
    "                  transforms.CenterCrop(height),\n",
    "                  # 水平方向の反転\n",
    "                  transforms.RandomHorizontalFlip(0.5),\n",
    "                  # 斜めにするなら↓\n",
    "                  #transforms.RandomRotation(degrees=20)\n",
    "                  #transforms.Lambda(lambda x: nn.functional.interpolate(x, (height,width)))\n",
    "])\n",
    "\n",
    "# テストデータの編集\n",
    "transform_test = transforms.Compose([\n",
    "                 PadFrames(frames_per_clip=frames_per_clip),\n",
    "                 # TODO: this should be done by a video-level transfrom when PyTorch provides transforms.ToTensor() for video transforms.ToTensor(),\n",
    "                 # scale in [0, 1] of type float\n",
    "                 transforms.Lambda(lambda x: x / 255.0),\n",
    "                 # reshape into (T, C, H, W) for easier convolutions\n",
    "                 transforms.Lambda(lambda x: x.permute(3, 0, 1, 2)),\n",
    "                 # rescale to the most common size\n",
    "                 transforms.Lambda(lambda x: nn.functional.interpolate(x, (height,width)))\n",
    "])\n",
    "\n",
    "# We also need a custom collation function in order to deal with videos with different number of audio channels (none, mono, stereo, etc.):\n",
    "# 複数の種類のデータから動画を選択するのに必要？\n",
    "def custom_collate(batch):\n",
    "    filtered_batch = []\n",
    "    for video, _, label in batch:\n",
    "        filtered_batch.append((video, label))\n",
    "    return torch.utils.data.dataloader.default_collate(filtered_batch)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b52bb3d-549d-4276-b40e-73d505e91e85",
   "metadata": {},
   "source": [
    "データセットの作成"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2438a8cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 訓練用データの読み込み(セット)\n",
    "train_dataset = torchvision.datasets.UCF101(\n",
    "    root=root,                                          # データの保存先のディレクトリ\n",
    "    annotation_path=root_label,                         # データラベルのディレクトリ\n",
    "    frames_per_clip=frames_per_clip,                    # 動画ごとのフレーム数(時間)\n",
    "    step_between_clips=step_between_clips,              # 動画間の長さ\n",
    "    train=True,                                         # 訓練データを指定\n",
    "    transform=transform_train,                          # トランスフォーマーオブジェクトを指定\n",
    "    num_workers=2\n",
    ")\n",
    "\n",
    "# テスト用データの読み込み(セット)\n",
    "test_dataset = torchvision.datasets.UCF101(\n",
    "    root=root,                                          # データの保存先のディレクトリ\n",
    "    annotation_path=root_label,                         # データラベルのディレクトリ\n",
    "    frames_per_clip=frames_per_clip,                    # 動画ごとのフレーム数(時間)\n",
    "    step_between_clips=step_between_clips,              # 動画間の長さ\n",
    "    train=False,                                        # testデータを指定\n",
    "    transform=transform_test,                           # トランスフォーマーオブジェクトを指定\n",
    "    num_workers=2\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c611e96c-8617-4f74-ab3c-c8ef22174134",
   "metadata": {},
   "source": [
    "データローダーの作成"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8ea8466",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 訓練用のデータローダー\n",
    "train_dataloader = torch.utils.data.DataLoader(train_dataset,                  # 訓練データ\n",
    "                                               batch_size=batch_size,          # ミニバッチのサイズ\n",
    "                                               shuffle=True,                   # シャッフルして抽出\n",
    "                                               collate_fn=custom_collate,\n",
    "                                               #num_workers=2,\n",
    "                                               pin_memory=True\n",
    "                                              )\n",
    "# テスト用のデータローダー\n",
    "test_dataloader = torch.utils.data.DataLoader(test_dataset,                    # テストデータ\n",
    "                                              batch_size=batch_size,           # ミニバッチのサイズ\n",
    "                                              shuffle=True,                    # シャッフルして抽出\n",
    "                                              collate_fn=custom_collate,\n",
    "                                              #num_workers=2,\n",
    "                                              pin_memory=True\n",
    "                                             )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38b01c78-31a4-49ef-a1ea-3bc6ebcb23a7",
   "metadata": {},
   "source": [
    "使用するデータサイズの確認"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c674ca29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# データ数の表示\n",
    "print(f\"Total number of train samples: {len(train_dataset)}\")\n",
    "print(f\"Total number of test samples: {len(test_dataset)}\")\n",
    "print(f\"Total number of (train) batches: {len(train_dataloader)}\")\n",
    "print(f\"Total number of (test) batches: {len(test_dataloader)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e7509be-447f-47bb-bb0d-ff1e0e9326ec",
   "metadata": {},
   "source": [
    "使用する動画のサンプルを表示"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a65a41c1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 動画の次元を表示\n",
    "example_img = train_dataset[3000][0].to('cpu').detach().numpy().copy()\n",
    "print(example_img.shape)\n",
    "\n",
    "# 複数フレームの表示\n",
    "im_array = example_img.transpose(1,2,3,0).copy()\n",
    "print(im_array[0,:,:,:].shape)\n",
    "plt.imshow(im_array[0,:,:,:])\n",
    "\n",
    "row = int(frames_per_clip/8)+1 # グラフの行数\n",
    "col = 8                      # グラフの列数\n",
    "fig = plt.figure(figsize=(10,10))\n",
    "\n",
    "for m in range(row):\n",
    "    for n in range(col):\n",
    "        if(m*8+n+1>75):\n",
    "            break\n",
    "        ax = fig.add_subplot(row, col, m*8+n+1)\n",
    "        ax.imshow(im_array[m*8+n,:,:,:])\n",
    "        ax.axis(\"off\")\n",
    "\n",
    "#plt.suptitle(\"title\",fontsize=20)\n",
    "plt.subplots_adjust(wspace=0.1,hspace=0.1,bottom=0.1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32186b3e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f83560a4-c76a-43fa-85dd-aaf195113762",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# 2. モデルの定義・生成"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2360d9ba-1e12-4218-ba8f-23aa0d68044f",
   "metadata": {},
   "source": [
    "Parallel-3DCNNの定義"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "216522d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ベースとなる畳み込み層の設定\n",
    "class BasicConv3d(nn.Module):\n",
    "    def __init__(self, input_size, output_size, kernel_size, stride, padding=0):\n",
    "        super(BasicConv3d, self).__init__()\n",
    "        self.conv = nn.Conv3d(input_size, output_size, kernel_size=kernel_size, stride=stride, padding=padding,\n",
    "                              bias=False)  \n",
    "        self.bn = nn.BatchNorm3d(output_size, eps=1e-3, momentum=0.001, affine=True)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv(x)\n",
    "        x = self.bn(x)\n",
    "        x = self.relu(x)\n",
    "        \n",
    "        return x\n",
    "\n",
    "# メインモデル\n",
    "class Parallel_CNN_3D(nn.Module):\n",
    "    \n",
    "    \"\"\"\n",
    "    Attributes:\n",
    "        stream0,stream1:(\n",
    "            conv1\n",
    "            maxpool1\n",
    "            conv2\n",
    "            maxpool2\n",
    "            conv3\n",
    "            maxpool3\n",
    "            conv4a\n",
    "            conv4b\n",
    "            maxpool4\n",
    "            conv5a\n",
    "            conv5b\n",
    "            maxpool5\n",
    "            dropout(50%)\n",
    "        )connect\n",
    "        fc1\n",
    "        fc2\n",
    "        fc3\n",
    "    \"\"\"\n",
    "    \n",
    "\n",
    "    def __init__(self, num_classes=101, dropout_drop_prob = 0.5, input_channel = 3, spatial_squeeze=True):\n",
    "        super().__init__()\n",
    "        ## stream0\n",
    "        self.features0 = nn.Sequential(\n",
    "            # (3,75,255,255)→(num_channel,71,247,247)\n",
    "            BasicConv3d(input_channel, num_channel, kernel_size=(11,11,11), stride=(1,1,1), padding=(1,1,1)),\n",
    "            \n",
    "            # (num_channel,71,247,247)→(num_channel,25,81,81)\n",
    "            nn.MaxPool3d(kernel_size=(5,9,9), stride=(3,3,3), padding=(2,1,1)),\n",
    "            \n",
    "            # (num_channel,25,81,81)→(num_channel×2,25,77,77)\n",
    "            BasicConv3d(num_channel, num_channel*2, kernel_size=(3,7,7), stride=(1,1,1), padding=(1,1,1)), \n",
    "            \n",
    "            # (num_channel×2,25,77,77)→(num_channel×2,12,25,25)\n",
    "            nn.MaxPool3d(kernel_size=(3,7,7), stride=(2,3,3), padding=(1,1,1)), \n",
    "\n",
    "            # (num_channel×2,12,25,25)→(num_channel×2,12,25,25)\n",
    "            BasicConv3d(num_channel*2, num_channel*2, kernel_size=(5,5,5), stride=(1,1,1), padding=(2,2,2)),\n",
    "            \n",
    "            # (num_channel×2,12,25,25)→(num_channel×4,12,25,25)\n",
    "            BasicConv3d(num_channel*2, num_channel*4, kernel_size=(3,3,3), stride=(1,1,1), padding=(1,1,1)),\n",
    "            \n",
    "            # (num_channel×4,12,25,25)→(num_channel×4,6,9,9)\n",
    "            nn.MaxPool3d(kernel_size=(2,3,3), stride=(2,3,3), padding=(0,1,1)),\n",
    "            \n",
    "            # (num_channel×4,6,9,9)→(num_channel×6,6,9,9)\n",
    "            BasicConv3d(num_channel*4, num_channel*6, kernel_size=(5,5,5), stride=(1,1,1), padding=(2,2,2)),\n",
    "            \n",
    "            # (num_channel×6,6,9,9)→(num_channel×8,6,9,9)\n",
    "            BasicConv3d(num_channel*6, num_channel*8, kernel_size=(3,3,3), stride=(1,1,1), padding=(1,1,1)),\n",
    "            \n",
    "            # (num_channel×8,6,9,9)→(num_channel×8,3,5,5)\n",
    "            nn.MaxPool3d(kernel_size=(2,3,3), stride=(2,2,2), padding=(0,1,1)),\n",
    "            \n",
    "            # (num_channel×8,3,5,5)→(num_channel×8,3,5,5)\n",
    "            BasicConv3d(num_channel*8, num_channel*8, kernel_size=(5,5,5), stride=(1,1,1), padding=(2,2,2)),\n",
    "            \n",
    "            # (num_channel×8,3,5,5)→(num_channel×8,3,5,5)\n",
    "            BasicConv3d(num_channel*8, num_channel*8, kernel_size=(3,3,3), stride=(1,1,1), padding=(1,1,1)),\n",
    "            \n",
    "            # (num_channel×8,3,5,5)→(num_channel×8,2,3,3)\n",
    "            nn.MaxPool3d(kernel_size=(3,3,3), stride=(2,2,2), padding=(1,1,1)),\n",
    "            \n",
    "            nn.Dropout3d(dropout_drop_prob),\n",
    "        )\n",
    "        \n",
    "        ## stream1\n",
    "        self.features1 = nn.Sequential(\n",
    "            # (3,75,255,255)→(num_channel,71,247,247)\n",
    "            BasicConv3d(input_channel, num_channel, kernel_size=(11,11,11), stride=(1,1,1), padding=(1,1,1)),\n",
    "            \n",
    "            # (num_channel,71,247,247)→(num_channel,25,81,81)\n",
    "            nn.MaxPool3d(kernel_size=(5,9,9), stride=(3,3,3), padding=(2,1,1)),\n",
    "            \n",
    "            # (num_channel,25,81,81)→(num_channel×2,25,77,77)\n",
    "            BasicConv3d(num_channel, num_channel*2, kernel_size=(3,7,7), stride=(1,1,1), padding=(1,1,1)), \n",
    "            \n",
    "            # (num_channel×2,25,77,77)→(num_channel×2,12,25,25)\n",
    "            nn.MaxPool3d(kernel_size=(3,7,7), stride=(2,3,3), padding=(1,1,1)), \n",
    "\n",
    "            # (num_channel×2,12,25,25)→(num_channel×2,12,25,25)\n",
    "            BasicConv3d(num_channel*2, num_channel*2, kernel_size=(5,5,5), stride=(1,1,1), padding=(2,2,2)),\n",
    "            \n",
    "            # (num_channel×2,12,25,25)→(num_channel×4,12,25,25)\n",
    "            BasicConv3d(num_channel*2, num_channel*4, kernel_size=(3,3,3), stride=(1,1,1), padding=(1,1,1)),\n",
    "            \n",
    "            # (num_channel×4,12,25,25)→(num_channel×4,6,9,9)\n",
    "            nn.MaxPool3d(kernel_size=(2,3,3), stride=(2,3,3), padding=(0,1,1)),\n",
    "            \n",
    "            # (num_channel×4,6,9,9)→(num_channel×6,6,9,9)\n",
    "            BasicConv3d(num_channel*4, num_channel*6, kernel_size=(5,5,5), stride=(1,1,1), padding=(2,2,2)),\n",
    "            \n",
    "            # (num_channel×6,6,9,9)→(num_channel×8,6,9,9)\n",
    "            BasicConv3d(num_channel*6, num_channel*8, kernel_size=(3,3,3), stride=(1,1,1), padding=(1,1,1)),\n",
    "            \n",
    "            # (num_channel×8,6,9,9)→(num_channel×8,3,5,5)\n",
    "            nn.MaxPool3d(kernel_size=(2,3,3), stride=(2,2,2), padding=(0,1,1)),\n",
    "            \n",
    "            # (num_channel×8,3,5,5)→(num_channel×8,3,5,5)\n",
    "            BasicConv3d(num_channel*8, num_channel*8, kernel_size=(5,5,5), stride=(1,1,1), padding=(2,2,2)),\n",
    "            \n",
    "            # (num_channel×8,3,5,5)→(num_channel×8,3,5,5)\n",
    "            BasicConv3d(num_channel*8, num_channel*8, kernel_size=(3,3,3), stride=(1,1,1), padding=(1,1,1)),\n",
    "            \n",
    "            # (num_channel×8,3,5,5)→(num_channel×8,2,3,3)\n",
    "            nn.MaxPool3d(kernel_size=(3,3,3), stride=(2,2,2), padding=(1,1,1)),\n",
    "            \n",
    "            nn.Dropout3d(dropout_drop_prob),\n",
    "        )\n",
    "        \n",
    "        ## after connection\n",
    "        # (256,2x3x3 + 256,2x3x3) -> (4096)\n",
    "        self.fc1 = nn.Linear(256*2*3*3 *2, 4096)\n",
    "        self.dropout2 = nn.Dropout()\n",
    "        # (4096) -> (1024)\n",
    "        self.fc2 = nn.Linear(4096, 1024)\n",
    "        # (1024) -> (num_classes)\n",
    "        self.fc3 = nn.Linear(1024, num_classes)\n",
    " \n",
    "        # 初期値設定\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv3d):\n",
    "                nn.init.kaiming_normal_(m.weight, mode=\"fan_out\", nonlinearity=\"relu\")\n",
    "                if m.bias is not None:\n",
    "                    nn.init.constant_(m.bias, 0)\n",
    "            elif isinstance(m, nn.BatchNorm3d):\n",
    "                nn.init.constant_(m.weight, 1)\n",
    "                nn.init.constant_(m.bias, 0)\n",
    "            elif isinstance(m, nn.Linear):\n",
    "                nn.init.normal_(m.weight, 0, 0.01)\n",
    "                nn.init.constant_(m.bias, 0)\n",
    "        \n",
    "        \n",
    "    def forward(self, x):\n",
    "        x0 = self.features0(x)\n",
    "        x1 = self.features1(x)\n",
    "        ##\n",
    "        x0 = x0.view(-1, num_channel*8*2*3*3)\n",
    "        x1 = x1.view(-1, num_channel*8*2*3*3)\n",
    "        xc = torch.cat((x0, x1), dim=1)\n",
    "        xc = torch.relu(self.fc1(xc))\n",
    "        xc = self.dropout2(xc)\n",
    "        xc = torch.relu(self.fc2(xc))\n",
    "        out = self.fc3(xc)\n",
    "            \n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c372d2fa-2b71-4056-8726-957a50534dc9",
   "metadata": {},
   "source": [
    "モデルを適用し、生成・確認する"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89d5297d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 使用可能なデバイス(CPUまたはGPU）を取得する\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(\"device:\",device)\n",
    "# モデルオブジェクトを生成し、使用可能なデバイスを設定する\n",
    "model = Parallel_CNN_3D().to(device)\n",
    "#model.load_state_dict(torch.load('Parallel_3DCNN_00_weight_before.pth'))\n",
    "\n",
    "# modelの構造を確認するなら↓\n",
    "#model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02726092-7657-4279-bf26-b604c4c3abcf",
   "metadata": {},
   "source": [
    "適当な値を入力させて、エラーが発生しないことを確認"
   ]
  },
  {
   "cell_type": "raw",
   "id": "6a1bcc41",
   "metadata": {},
   "source": [
    "# ダミー入力データを作成 (バッチサイズ=3, チャンネル=3, 深さ(時間), 高さ, 幅)\n",
    "input_data = torch.randn(3, 3, frames_per_clip, height, width).to(device)\n",
    "\n",
    "# モデルに入力データを通して動作確認\n",
    "output = model(input_data).to(device)\n",
    "print(output.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19f586b0-03b8-4f89-af30-df3cc7a497d5",
   "metadata": {},
   "source": [
    "モデルのパラメータを保存"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d31fe301",
   "metadata": {},
   "outputs": [],
   "source": [
    "# モデルデータの保存は↓\n",
    "torch.save(model.state_dict(), 'Parallel_3DCNN_00_weight_before.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc071de7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "dbad0cfb-c315-4e83-8a16-fdfb4c397ebd",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# 3. モデルの可視化"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79deee3d-efeb-401b-b0b0-1d009ba02409",
   "metadata": {},
   "source": [
    "畳み込み層第1層の可視化を行う"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9ced167",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TW面(H=0)の可視化\n",
    "def filter_show_TW(filters, nx=8, margin=3, scale=10):\n",
    "    # 畳み込み層第1層のパラメータをそれぞれ抽出する\n",
    "    FN, C, FT, FH, FW = filters.shape\n",
    "    ny = int(np.ceil(FN / nx))\n",
    "    \n",
    "    # H=0のときのパラメータを選択\n",
    "    filter_choice = filters[:,:,:,0,:].copy()\n",
    "    print(filter_choice.shape)\n",
    "    # (N,C,T,W)→→(N,T,W,C)\n",
    "    filter_choice = filter_choice.transpose(0,2,3,1)\n",
    "\n",
    "    # matplotlibで表示\n",
    "    fig = plt.figure(figsize=(10,5))\n",
    "    plt.title(\"x:time,y:width\",fontsize=10)\n",
    "    plt.axis(\"off\")\n",
    "    fig.subplots_adjust(left=0, right=0.9, bottom=0, top=1, hspace=0.05, wspace=0.05)\n",
    "    \n",
    "    for i in range(FN):\n",
    "        if i < nx * ny:\n",
    "            ax = fig.add_subplot(ny, nx, i+1, xticks=[], yticks=[])\n",
    "            filter_img = filter_choice[i,:,:,:] \n",
    "            filter_img = (filter_img - filter_choice.min()) / (filter_choice.max() - filter_choice.min())  # 正規化\n",
    "            img = ax.imshow(filter_img, interpolation='nearest')\n",
    "            \n",
    "    plt.show()\n",
    "    \n",
    "    \n",
    "# TH面(W=0)の可視化\n",
    "def filter_show_TH(filters, nx=8, margin=3, scale=10):\n",
    "\n",
    "    FN, C, FT, FH, FW = filters.shape\n",
    "    ny = int(np.ceil(FN / nx))\n",
    "    \n",
    "    # W=0\n",
    "    filter_choice = filters[:,:,:,:,0].copy()\n",
    "    print(filter_choice.shape)\n",
    "    # (N,C,T,H)→→(N,T,H,C)\n",
    "    filter_choice = filter_choice.transpose(0,2,3,1)\n",
    "\n",
    "    fig = plt.figure(figsize=(10,5))\n",
    "    plt.title(\"x:time,y:height\",fontsize=10)\n",
    "    plt.axis(\"off\")\n",
    "    fig.subplots_adjust(left=0, right=0.9, bottom=0, top=1, hspace=0.05, wspace=0.05)\n",
    "    \n",
    "    for i in range(FN):\n",
    "        if i < nx * ny:\n",
    "            ax = fig.add_subplot(ny, nx, i+1, xticks=[], yticks=[])\n",
    "            filter_img = filter_choice[i,:,:,:] \n",
    "            filter_img = (filter_img - filter_choice.min()) / (filter_choice.max() - filter_choice.min())  # 正規化\n",
    "            img = ax.imshow(filter_img, interpolation='nearest')\n",
    "            \n",
    "    plt.show()\n",
    "    \n",
    "\n",
    "# WH面(T=0)の可視化\n",
    "def filter_show_WH(filters, nx=8, margin=3, scale=10):\n",
    "\n",
    "    FN, C, FT, FH, FW = filters.shape\n",
    "    ny = int(np.ceil(FN / nx))\n",
    "    \n",
    "    # T=0\n",
    "    filter_choice = filters[:,:,0,:,:].copy()\n",
    "    print(filter_choice.shape)\n",
    "    # (N,C,H,W)→→(N,W,H,C)\n",
    "    filter_choice = filter_choice.transpose(0,3,2,1)\n",
    "\n",
    "    fig = plt.figure(figsize=(10,5))\n",
    "    plt.title(\"x:width,y:height\",fontsize=10)\n",
    "    plt.axis(\"off\")\n",
    "    fig.subplots_adjust(left=0, right=0.9, bottom=0, top=1, hspace=0.05, wspace=0.05)\n",
    "    \n",
    "    for i in range(FN):\n",
    "        if i < nx * ny:\n",
    "            ax = fig.add_subplot(ny, nx, i+1, xticks=[], yticks=[])\n",
    "            filter_img = filter_choice[i,:,:,:] # 高さと深さの次元を選択し、幅の次元は0に固定する\n",
    "            filter_img = (filter_img - filter_choice.min()) / (filter_choice.max() - filter_choice.min())  # 正規化\n",
    "            img = ax.imshow(filter_img, interpolation='nearest')\n",
    "            \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25042b05-6b85-4aa9-b27e-30219c21ffdd",
   "metadata": {},
   "source": [
    "経路0の畳み込み層第1層のフィルタの各平面表示"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15b4dd33",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(\"Branch0_WH\")\n",
    "filter_show_WH(model.features0[0].conv.weight.detach().cpu().numpy())\n",
    "print(\"Branch0_TH\")\n",
    "filter_show_TH(model.features0[0].conv.weight.detach().cpu().numpy())\n",
    "print(\"Branch0_TW\")\n",
    "filter_show_TW(model.features0[0].conv.weight.detach().cpu().numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d880e964-b7aa-454e-bc79-4bcb84e7dcd3",
   "metadata": {},
   "source": [
    "経路1の畳み込み層第1層のフィルタの各平面表示"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef0912a9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(\"Branch1_WH\")\n",
    "filter_show_WH(model.features1[0].conv.weight.detach().cpu().numpy())\n",
    "print(\"Branch1_TH\")\n",
    "filter_show_TH(model.features1[0].conv.weight.detach().cpu().numpy())\n",
    "print(\"Branch1_TW\")\n",
    "filter_show_TW(model.features1[0].conv.weight.detach().cpu().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7848e787-b2e7-4406-8ff3-0c4ad68a5149",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "20da8690-fef2-4d81-8c2c-faf55d9d69a3",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# 4. 損失関数やパラメーターの設定"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "796130ff-a50b-4853-b0a5-ddd5314d9e16",
   "metadata": {},
   "source": [
    "損失関数・オプティマイザーの設定"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01a60cdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim\n",
    "\n",
    "# クロスエントロピー誤差のオブジェクトを生成\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "# 勾配降下アルゴリズムを使用するオプティマイザーを生成\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.001, momentum=0.9)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a622af0d-3265-4b5e-892a-987460312a92",
   "metadata": {},
   "source": [
    "モデル訓練(学習)時の設定"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89ef4575",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_step(x, t):\n",
    "    '''バックプロパゲーションによるパラメーター更新を行う\n",
    "    \n",
    "    Parameters: x: 訓練データ\n",
    "                t: 正解ラベル                \n",
    "    Returns:\n",
    "      MLPの出力と正解ラベルのクロスエントロピー誤差\n",
    "    '''\n",
    "    model.train()    # モデルを訓練(学習)モードにする\n",
    "    preds = model(x) # モデルの出力を取得\n",
    "    loss = criterion(preds, t) # 出力と正解ラベルの誤差から損失を取得\n",
    "    optimizer.zero_grad() # 勾配を0で初期化（累積してしまうため）\n",
    "    loss.backward()  # 逆伝播の処理(自動微分による勾配計算)\n",
    "    optimizer.step() # 勾配降下法の更新式を適用してバイアス、重みを更新\n",
    "\n",
    "    return loss, preds "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1bbe274-bffd-477c-95e7-125d76be8bdb",
   "metadata": {},
   "source": [
    "モデルテスト時の設定"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fc88e9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_step(x, t):\n",
    "    '''テストデータを入力して損失と予測値を返す\n",
    "    \n",
    "    Parameters: x: テストデータ\n",
    "                t: 正解ラベル\n",
    "    Returns:\n",
    "      MLPの出力と正解ラベルのクロスエントロピー誤差\n",
    "    '''\n",
    "    model.eval()     # モデルを評価モードにする\n",
    "    preds = model(x) # モデルの出力を取得\n",
    "    loss = criterion(preds, t) # 出力と正解ラベルの誤差から損失を取得\n",
    "\n",
    "    return loss, preds "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "388d5708-2272-4a5b-84e5-6f662b5d4727",
   "metadata": {},
   "source": [
    "訓練時に文字数制限などで発生するエラーを無視"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ef7775e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.simplefilter('ignore', UserWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fbc17f8-7cb5-4b9f-86eb-e8f73e4a0f16",
   "metadata": {},
   "source": [
    "経過時間・進行度を表示"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b2e9fc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "import datetime\n",
    "dt_now = datetime.datetime.now()\n",
    "print(dt_now)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6144be1-763e-42a1-ae47-139af5b997de",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "78a7c75d-b0b0-4cff-90f8-0f9c94422d60",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# 5. モデルの学習"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6900a76b-f4ce-43aa-bdce-e233c2828907",
   "metadata": {},
   "source": [
    "モデルの訓練(学習)・テスト"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52f7683b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# エポック数\n",
    "epochs = epoch_num\n",
    "# 損失と精度の履歴を保存するためのdictオブジェクト\n",
    "history = {'loss':[],'accuracy':[], 'test_loss':[], 'test_accuracy':[], 'top5_accuracy':[]}\n",
    "\n",
    "# 収束が停滞したら学習率を減衰するスケジューラー\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
    "    optimizer,   # オプティマイザーを指定\n",
    "    mode='max',  # 監視対象は最大値\n",
    "    factor=0.5,  # 学習率を減衰する割合\n",
    "    patience=5, # 監視対象のエポック数\n",
    "    min_lr=0.0001, # 最小学習率\n",
    "    verbose=True # 学習率を減衰した場合に通知する\n",
    "    )\n",
    "\n",
    "# Top-5精度の計算器\n",
    "top5_acc = Accuracy(top_k=5, task='multiclass', num_classes=label_num).to(device)\n",
    "\n",
    "# 学習を行う\n",
    "for epoch in tqdm(range(epochs)):\n",
    "    train_loss = 0. # 訓練1エポックあたりの損失を保持する変数\n",
    "    train_acc = 0.  # 訓練1エポックごとの精度を保持する変数\n",
    "    test_loss = 0.  # 評価1エポックごとの損失を保持する変数\n",
    "    test_acc = 0.   # 評価1エポックごとの精度を保持する変数\n",
    "    test_top5_acc = 0.   # 評価1エポックごとの精度(top5)を保持する変数\n",
    "\n",
    "    # 1ステップにおける訓練用ミニバッチを使用した学習\n",
    "    for (x, t) in tqdm(train_dataloader, mininterval=3600):\n",
    "        # torch.Tensorオブジェクトにデバイスを割り当てる\n",
    "        x, t = x.to(device), t.to(device)\n",
    "        loss, preds = train_step(x, t) # 損失と予測値を取得\n",
    "        train_loss += loss.item()      # ステップごとの損失を加算\n",
    "        train_acc += accuracy_score(\n",
    "            t.tolist(),\n",
    "            preds.argmax(dim=-1).tolist()\n",
    "        )   # ステップごとの精度を加算\n",
    "        \n",
    "    # 1ステップにおけるテストデータのミニバッチを使用した評価\n",
    "    for (x, t) in test_dataloader:\n",
    "        # torch.Tensorオブジェクトにデバイスを割り当てる\n",
    "        x, t = x.to(device), t.to(device)\n",
    "        loss, preds = test_step(x, t) # 損失と予測値を取得\n",
    "        test_loss += loss.item()       # ステップごとの損失を加算\n",
    "        t_tensor = t.cuda()\n",
    "        preds_tensor = preds.cuda()\n",
    "        t_numpy = t_tensor.cpu().detach().numpy()\n",
    "        preds_numpy = preds_tensor.cpu().detach().numpy()\n",
    "        \n",
    "        test_acc += accuracy_score(\n",
    "            t.tolist(),\n",
    "            preds.argmax(dim=-1).tolist()\n",
    "        )                              # ステップごとの精度を加算\n",
    "        test_top5_acc += top5_acc(preds, t).item()\n",
    "\n",
    "        \n",
    "    # 訓練時の損失の平均値を取得\n",
    "    avg_train_loss = train_loss / len(train_dataloader)\n",
    "    # 訓練時の精度の平均値を取得\n",
    "    avg_train_acc = train_acc / len(train_dataloader)\n",
    "    # 検証時の損失の平均値を取得\n",
    "    avg_test_loss = test_loss / len(test_dataloader)\n",
    "    # 検証時の精度の平均値を取得\n",
    "    avg_test_acc = test_acc / len(test_dataloader)\n",
    "    # top5の精度の平均値を取得\n",
    "    avg_top5_acc = test_top5_acc / len(test_dataloader)\n",
    "\n",
    "    # 訓練データの履歴を保存する\n",
    "    history['loss'].append(avg_train_loss)\n",
    "    history['accuracy'].append(avg_train_acc)\n",
    "    # テストデータの履歴を保存する\n",
    "    history['test_loss'].append(avg_test_loss)\n",
    "    history['test_accuracy'].append(avg_test_acc)\n",
    "    history['top5_accuracy'].append(avg_top5_acc)\n",
    "\n",
    "    # 1エポックごとに結果を出力\n",
    "    if (epoch + 1) % 1 == 0:\n",
    "        print(\n",
    "            'epoch({}) train_loss: {:.6} train_acc: {:.6} val_loss: {:.6} val_acc: {:.6} val_top5: {:.6}'.format(\n",
    "                epoch+1,\n",
    "                avg_train_loss, # 訓練データの損失を出力\n",
    "                avg_train_acc,  # 訓練データの精度を出力\n",
    "                avg_test_loss,  # テストデータの損失を出力\n",
    "                avg_test_acc,   # テストデータの精度を出力\n",
    "                avg_top5_acc    # top5の精度を出力\n",
    "    ))\n",
    "    # スケジューラー、テストデータの精度を監視する\n",
    "    scheduler.step(avg_test_acc)\n",
    "    dt_now = datetime.datetime.now()\n",
    "    print(dt_now)\n",
    "    \n",
    "    # エポックごとにモデルのパラメータを保存\n",
    "    filename = \"Parallel_3DCNN_\" + str(epoch+1).zfill(2) + \"_weight_after.pth\"\n",
    "    torch.save(model.state_dict(), filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3438fa63-c36e-449e-a163-deca7ca20812",
   "metadata": {},
   "source": [
    "最後のパラメータを保存する場合"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3aa76237",
   "metadata": {},
   "outputs": [],
   "source": [
    "# モデルデータの保存は↓\n",
    "#torch.save(model.state_dict(), 'Parallel_3DCNN_00_weight_after.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "906f30fb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b9b10b7f-3c53-4cdc-bf87-540c8932fc17",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# 6. 損失と精度"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4a0f4ac-b440-4336-b8d3-4303e75f18e2",
   "metadata": {},
   "source": [
    "結果をグラフに表示する"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a1edeca",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# 学習結果（損失）のグラフを描画\n",
    "plt.plot(history['loss'],\n",
    "         marker='.',\n",
    "         label='loss (Training)')\n",
    "plt.plot(history['test_loss'],\n",
    "         marker='.',\n",
    "         label='loss (Test)')\n",
    "plt.legend(loc='best')\n",
    "plt.grid()\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('loss')\n",
    "plt.show()\n",
    "\n",
    "# 学習結果（精度）のグラフを描画\n",
    "plt.plot(history['accuracy'],\n",
    "         marker='.',\n",
    "         label='accuracy (Training)')\n",
    "plt.plot(history['test_accuracy'],\n",
    "         marker='.',\n",
    "         label='accuracy (Test)')\n",
    "plt.plot(history['top5_accuracy'],\n",
    "         marker='.',\n",
    "         label='accuracy(Test_top5)')\n",
    "plt.legend(loc='best')\n",
    "plt.grid()\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('accuracy')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43096199-17b9-4bea-a856-13052076e49c",
   "metadata": {},
   "source": [
    "エポックごとの数値を表示する"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d954b8b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"history['loss']\")\n",
    "print(history['loss'])\n",
    "print(\"history['test_loss']\")\n",
    "print(history['test_loss'])\n",
    "print(\"history['accuracy']\")\n",
    "print(history['accuracy'])\n",
    "print(\"history['test_accuracy']\")\n",
    "print(history['test_accuracy'])\n",
    "print(\"history['top5_accuracy']\")\n",
    "print(history['top5_accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70e27983",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9a416308-5402-436e-bb6d-43c3392ccfd2",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# 7. 結果"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1219299b-7674-4dfc-8d76-ff17c42c6a6d",
   "metadata": {},
   "source": [
    "訓練(学習)後のフィルタの様子"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb3a960b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 経路0\n",
    "print(\"Branch0_WH\")\n",
    "filter_show_WH(model.features0[0].conv.weight.detach().cpu().numpy())\n",
    "print(\"Branch0_TH\")\n",
    "filter_show_TH(model.features0[0].conv.weight.detach().cpu().numpy())\n",
    "print(\"Branch0_TW\")\n",
    "filter_show_TW(model.features0[0].conv.weight.detach().cpu().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f86216d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 経路1\n",
    "print(\"Branch1_WH\")\n",
    "filter_show_WH(model.features1[0].conv.weight.detach().cpu().numpy())\n",
    "print(\"Branch1_TH\")\n",
    "filter_show_TH(model.features1[0].conv.weight.detach().cpu().numpy())\n",
    "print(\"Branch1_TW\")\n",
    "filter_show_TW(model.features1[0].conv.weight.detach().cpu().numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "814f014d-a6da-435b-b634-9b167d939b30",
   "metadata": {},
   "source": [
    "フィルタを各平面から見たときの軸変化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da97f447",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 指定したフィルタのT変化(WH平面)　複数ver.\n",
    "def filter_singlemoves_WH(filnums, filters, nx=11, margin=0.1, scale=10):\n",
    "\n",
    "    FN, C, FT, FH, FW = filters.shape\n",
    "    ny = len(filnums)\n",
    "    \n",
    "    fig = plt.figure(figsize=(11,30))\n",
    "    #plt.title(\"x:width,y:height\",fontsize=10)\n",
    "    plt.axis(\"off\")\n",
    "    fig.subplots_adjust(left=0, right=0.9, bottom=0, top=1, hspace=0.05, wspace=0.05)\n",
    "    \n",
    "    for j in range(ny):\n",
    "        filter_choice = filters[filnums[j]-1,:,:,:,:].copy()\n",
    "        filter_choice = filter_choice.transpose(3,2,1,0) #(WHTC)\n",
    "    \n",
    "    \n",
    "        for i in range(nx):\n",
    "            if i < nx:\n",
    "                all_filter_T = filters[:,:,i,:,:].copy()\n",
    "                all_filter_T = all_filter_T.transpose(0,3,2,1) #(NWHC)\n",
    "            \n",
    "                ax = fig.add_subplot(ny, nx, j*11+i+1, xticks=[], yticks=[])\n",
    "                filter_img = filter_choice[:,:,i,:] #(WHC)\n",
    "                filter_img = (filter_img - all_filter_T.min()) / (all_filter_T.max() - all_filter_T.min())  # 正規化\n",
    "                img = ax.imshow(filter_img, interpolation='nearest')\n",
    "            \n",
    "    plt.show()\n",
    "    \n",
    "    \n",
    "    \n",
    "# 指定したフィルタのW変化(TH平面)　複数ver.\n",
    "def filter_singlemoves_TH(filnums, filters, nx=11, margin=0.1, scale=10):\n",
    "\n",
    "    FN, C, FT, FH, FW = filters.shape\n",
    "    ny = len(filnums)\n",
    "    \n",
    "    fig = plt.figure(figsize=(11,30))\n",
    "    #plt.title(\"x:width,y:height\",fontsize=10)\n",
    "    plt.axis(\"off\")\n",
    "    fig.subplots_adjust(left=0, right=0.9, bottom=0, top=1, hspace=0.05, wspace=0.05)\n",
    "    \n",
    "    for j in range(ny):\n",
    "        filter_choice = filters[filnums[j]-1,:,:,:,:].copy()\n",
    "        filter_choice = filter_choice.transpose(1,2,3,0) #(THWC)\n",
    "    \n",
    "    \n",
    "        for i in range(nx):\n",
    "            if i < nx:\n",
    "                all_filter_W = filters[:,:,:,:,i].copy()\n",
    "                all_filter_W = all_filter_W.transpose(0,2,3,1) #(NTHC)\n",
    "            \n",
    "                ax = fig.add_subplot(ny, nx, j*11+i+1, xticks=[], yticks=[])\n",
    "                filter_img = filter_choice[:,:,i,:] #(THC)\n",
    "                filter_img = (filter_img - all_filter_W.min()) / (all_filter_W.max() - all_filter_W.min())  # 正規化\n",
    "                img = ax.imshow(filter_img, interpolation='nearest')\n",
    "            \n",
    "    plt.show()\n",
    "\n",
    "# 指定したフィルタのH変化(TW平面)　複数ver.\n",
    "def filter_singlemoves_TW(filnums, filters, nx=11, margin=0.1, scale=10):\n",
    "\n",
    "    FN, C, FT, FH, FW = filters.shape\n",
    "    ny = len(filnums)\n",
    "    \n",
    "    fig = plt.figure(figsize=(11,30))\n",
    "    #plt.title(\"x:width,y:height\",fontsize=10)\n",
    "    plt.axis(\"off\")\n",
    "    fig.subplots_adjust(left=0, right=0.9, bottom=0, top=1, hspace=0.05, wspace=0.05)\n",
    "    \n",
    "    for j in range(ny):\n",
    "        filter_choice = filters[filnums[j]-1,:,:,:,:].copy()\n",
    "        filter_choice = filter_choice.transpose(1,3,2,0) #(TWHC)\n",
    "    \n",
    "    \n",
    "        for i in range(nx):\n",
    "            if i < nx:\n",
    "                all_filter_H = filters[:,:,:,i,:].copy()\n",
    "                all_filter_H = all_filter_H.transpose(0,2,3,1) #(NTWC)\n",
    "            \n",
    "                ax = fig.add_subplot(ny, nx, j*11+i+1, xticks=[], yticks=[])\n",
    "                filter_img = filter_choice[:,:,i,:] #(TWC)\n",
    "                filter_img = (filter_img - all_filter_H.min()) / (all_filter_H.max() - all_filter_H.min())  # 正規化\n",
    "                img = ax.imshow(filter_img, interpolation='nearest')\n",
    "            \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bbeb755-5f84-47c8-b0c0-e6195ae92317",
   "metadata": {},
   "source": [
    "指定したフィルタのT変化(WH平面)、経路0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7f6eeb4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "filter_singlemoves_WH(np.arange(1,33),model.features0[0].conv.weight.detach().cpu().numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aae83dda-2db3-40c3-9d3a-d2b04a35c1d0",
   "metadata": {},
   "source": [
    "指定したフィルタのT変化(WH平面)、経路1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5005826",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "filter_singlemoves_WH(np.arange(1,33),model.features1[0].conv.weight.detach().cpu().numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d8c4ab6-659c-45c2-87f2-e9d4f1b7703e",
   "metadata": {},
   "source": [
    "指定したフィルタのW変化(TH平面)、経路0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "368d908b",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "filter_singlemoves_TH(np.arange(1,33),model.features0[0].conv.weight.detach().cpu().numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23cce7fc-3714-47aa-ab7f-0aabe1b7207f",
   "metadata": {},
   "source": [
    "指定したフィルタのW変化(TH平面)、経路1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd59a4d2",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "filter_singlemoves_TH(np.arange(1,33),model.features1[0].conv.weight.detach().cpu().numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2da9ef1-9962-4fa6-8ec4-090ccdb038e5",
   "metadata": {},
   "source": [
    "指定したフィルタのH変化(TW平面)、経路0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bc6cec2",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "filter_singlemoves_TW(np.arange(1,33),model.features0[0].conv.weight.detach().cpu().numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c683cb8-5eaa-4aa3-bd5e-02bb030b5545",
   "metadata": {},
   "source": [
    "指定したフィルタのH変化(TW平面)、経路1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73b90141",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "filter_singlemoves_TW(np.arange(1,33),model.features1[0].conv.weight.detach().cpu().numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e95f1a17-beae-49e5-9f72-d6b1563cc70f",
   "metadata": {},
   "source": [
    "指定したフィルタの各平面の拡大表示"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6cedcf9-d499-4ba8-ac59-4742aee79bc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_single(filters, filter_number, nx=3, margin=0.1, scale=10):\n",
    "\n",
    "    FN, C, FT, FH, FW = filters.shape\n",
    "    ny = 1\n",
    "\n",
    "    fig = plt.figure(figsize=(10,10))\n",
    "    plt.axis(\"off\")\n",
    "    fig.subplots_adjust(left=0, right=0.9, bottom=0, top=1, hspace=0.05, wspace=0.05)\n",
    "    \n",
    "    \n",
    "    for i in range(nx):\n",
    "        filter_choice = filters[filter_number-1,:,:,:,:].copy()\n",
    "        \n",
    "        if (i==0):\n",
    "            filter_choice = filter_choice.transpose(3,2,1,0) #WHTC\n",
    "            all_filter_1 = filters[:,:,0,:,:].copy()\n",
    "            all_filter_1 = all_filter_1.transpose(0,3,2,1) #NWHC\n",
    "            \n",
    "            ax = fig.add_subplot(ny, nx, i+1, xticks=[], yticks=[])\n",
    "            filter_img = filter_choice[:,:,0,:] #WHC\n",
    "            filter_img = (filter_img - all_filter_1.min()) / (all_filter_1.max() - all_filter_1.min())  # 正規化\n",
    "            img = ax.imshow(filter_img, interpolation='nearest')\n",
    "            \n",
    "        if (i==1):\n",
    "            filter_choice = filter_choice.transpose(1,3,2,0) #TWHC\n",
    "            all_filter_1 = filters[:,:,:,:,0].copy()\n",
    "            all_filter_1 = all_filter_1.transpose(0,2,3,1) #NTHC\n",
    "            \n",
    "            ax = fig.add_subplot(ny, nx, i+1, xticks=[], yticks=[])\n",
    "            filter_img = filter_choice[:,0,:,:] #THC\n",
    "            print(filter_img.shape)\n",
    "            filter_img = (filter_img - all_filter_1.min()) / (all_filter_1.max() - all_filter_1.min())  # 正規化\n",
    "            img = ax.imshow(filter_img, interpolation='nearest')\n",
    "        \n",
    "        if (i==2):\n",
    "            filter_choice = filter_choice.transpose(1,3,2,0) #TWHC\n",
    "            all_filter_1 = filters[:,:,:,0,:].copy()\n",
    "            all_filter_1 = all_filter_1.transpose(0,2,3,1) #NTWC\n",
    "            \n",
    "            ax = fig.add_subplot(ny, nx, i+1, xticks=[], yticks=[])\n",
    "            filter_img = filter_choice[:,:,0,:] #TWC\n",
    "            filter_img = (filter_img - all_filter_1.min()) / (all_filter_1.max() - all_filter_1.min())  # 正規化\n",
    "            img = ax.imshow(filter_img, interpolation='nearest')\n",
    "            \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7220b70e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"WH,TH,TW\")\n",
    "filter_single(model.features1[0].conv.weight.detach().cpu().numpy(), 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ab9fb02-a958-4212-8c10-6f7162d7addc",
   "metadata": {},
   "source": [
    "モノクロで2値化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3dd9ed0-b733-46ba-aeaf-427fc58f6c9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TW面(H=0)の可視化\n",
    "def filter_show_TWmono(filters, nx=8, margin=3, scale=10):\n",
    "\n",
    "    FN, C, FT, FH, FW = filters.shape\n",
    "    ny = int(np.ceil(FN / nx))\n",
    "    \n",
    "    # H=0\n",
    "    filter_choice = filters[:,:,:,0,:].copy()\n",
    "    print(filter_choice.shape)\n",
    "    # (N,C,T,W)→→(N,T,W,C)\n",
    "    filter_choice = filter_choice.transpose(0,2,3,1)\n",
    "\n",
    "    fig = plt.figure(figsize=(10,5))\n",
    "    plt.title(\"x:time,y:width\",fontsize=10)\n",
    "    plt.axis(\"off\")\n",
    "    fig.subplots_adjust(left=0, right=0.9, bottom=0, top=1, hspace=0.05, wspace=0.05)\n",
    "    \n",
    "    for i in range(FN):\n",
    "        if i < nx * ny:\n",
    "            ax = fig.add_subplot(ny, nx, i+1, xticks=[], yticks=[])\n",
    "            filter_img = filter_choice[i,:,:,:] \n",
    "            filter_img = (filter_img - filter_choice.min()) / (filter_choice.max() - filter_choice.min())  # 正規化\n",
    "            filter_img = (filter_img[:,:,0]+filter_img[:,:,1]+filter_img[:,:,2])/765\n",
    "            img = ax.imshow(filter_img, cmap='gray', interpolation='nearest')\n",
    "            \n",
    "    plt.show()\n",
    "    \n",
    "    \n",
    "# TH面(W=0)の可視化\n",
    "def filter_show_THmono(filters, nx=8, margin=3, scale=10):\n",
    "\n",
    "    FN, C, FT, FH, FW = filters.shape\n",
    "    ny = int(np.ceil(FN / nx))\n",
    "    \n",
    "    # W=0\n",
    "    filter_choice = filters[:,:,:,:,0].copy()\n",
    "    print(filter_choice.shape)\n",
    "    # (N,C,T,H)→→(N,T,H,C)\n",
    "    filter_choice = filter_choice.transpose(0,2,3,1)\n",
    "\n",
    "    fig = plt.figure(figsize=(10,5))\n",
    "    plt.title(\"x:time,y:height\",fontsize=10)\n",
    "    plt.axis(\"off\")\n",
    "    fig.subplots_adjust(left=0, right=0.9, bottom=0, top=1, hspace=0.05, wspace=0.05)\n",
    "    \n",
    "    for i in range(FN):\n",
    "        if i < nx * ny:\n",
    "            ax = fig.add_subplot(ny, nx, i+1, xticks=[], yticks=[])\n",
    "            filter_img = filter_choice[i,:,:,:] \n",
    "            filter_img = (filter_img - filter_choice.min()) / (filter_choice.max() - filter_choice.min())  # 正規化\n",
    "            filter_img = (filter_img[:,:,0]+filter_img[:,:,1]+filter_img[:,:,2])/765\n",
    "            img = ax.imshow(filter_img, cmap='gray', interpolation='nearest')\n",
    "            \n",
    "    plt.show()\n",
    "    \n",
    "\n",
    "# WH面(T=0)の可視化\n",
    "def filter_show_WHmono(filters, nx=8, margin=3, scale=10):\n",
    "\n",
    "    FN, C, FT, FH, FW = filters.shape\n",
    "    ny = int(np.ceil(FN / nx))\n",
    "    \n",
    "    # T=0\n",
    "    filter_choice = filters[:,:,0,:,:].copy()\n",
    "    print(filter_choice.shape)\n",
    "    # (N,C,H,W)→→(N,W,H,C)\n",
    "    filter_choice = filter_choice.transpose(0,3,2,1)\n",
    "\n",
    "    fig = plt.figure(figsize=(10, 5))\n",
    "    plt.title(\"x:width,y:height\",fontsize=10)\n",
    "    plt.axis(\"off\")\n",
    "    fig.subplots_adjust(left=0, right=0.9, bottom=0, top=1, hspace=0.05, wspace=0.05)\n",
    "    \n",
    "    for i in range(FN):\n",
    "        if i < nx * ny:\n",
    "            ax = fig.add_subplot(ny, nx, i+1, xticks=[], yticks=[])\n",
    "            filter_img = filter_choice[i,:,:,:] # 高さと深さの次元を選択し、幅の次元は0に固定する\n",
    "            filter_img = (filter_img - filter_choice.min()) / (filter_choice.max() - filter_choice.min())  # 正規化\n",
    "            filter_img = (filter_img[:,:,0]+filter_img[:,:,1]+filter_img[:,:,2])/765\n",
    "            img = ax.imshow(filter_img, cmap='gray', interpolation='nearest')\n",
    "            \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7bed6f0-0ef7-4116-b758-ea5176c36660",
   "metadata": {},
   "source": [
    "経路0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baedb688-0d71-4da2-9593-f1c677d82f0b",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "filter_show_WHmono(model.features0[0].conv.weight.detach().cpu().numpy())\n",
    "filter_show_THmono(model.features0[0].conv.weight.detach().cpu().numpy())\n",
    "filter_show_TWmono(model.features0[0].conv.weight.detach().cpu().numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbb853f5-4219-42f0-90c7-ed3ecc2e9671",
   "metadata": {
    "tags": []
   },
   "source": [
    "経路1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb31b111-d19c-4c33-89ea-cb24da2b80e9",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "filter_show_WHmono(model.features1[0].conv.weight.detach().cpu().numpy())\n",
    "filter_show_THmono(model.features1[0].conv.weight.detach().cpu().numpy())\n",
    "filter_show_TWmono(model.features1[0].conv.weight.detach().cpu().numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0111a27b-1567-4bbe-9220-87601df464de",
   "metadata": {},
   "source": [
    "フィルタを各平面から見たときの軸変化、モノクロ版"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b3b6d8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 指定したフィルタの時間変化(WH平面)　複数ver.mono\n",
    "def filter_singlemoves_WHmono(filnums, filters, nx=filter_size_conv1, margin=0.1, scale=10):\n",
    "\n",
    "    FN, C, FT, FH, FW = filters.shape\n",
    "    ny = len(filnums)\n",
    "    \n",
    "    fig = plt.figure(figsize=(11,30))\n",
    "    #plt.title(\"x:width,y:height\",fontsize=10)\n",
    "    plt.axis(\"off\")\n",
    "    fig.subplots_adjust(left=0, right=0.9, bottom=0, top=1, hspace=0.05, wspace=0.05)\n",
    "    \n",
    "    for j in range(ny):\n",
    "        filter_choice = filters[filnums[j]-1,:,:,:,:].copy()\n",
    "        filter_choice = filter_choice.transpose(3,2,1,0) #(WHTC)\n",
    "    \n",
    "    \n",
    "        for i in range(nx):\n",
    "            if i < nx:\n",
    "                all_filter_T = filters[:,:,i,:,:].copy()\n",
    "                all_filter_T = all_filter_T.transpose(0,3,2,1) #(NWHC)\n",
    "            \n",
    "                ax = fig.add_subplot(ny, nx, j*nx+i+1, xticks=[], yticks=[])\n",
    "                filter_img = filter_choice[:,:,i,:] #(WHC)\n",
    "                filter_img = (filter_img - all_filter_T.min()) / (all_filter_T.max() - all_filter_T.min())  # 正規化\n",
    "                filter_img = (filter_img[:,:,0]+filter_img[:,:,1]+filter_img[:,:,2])/765\n",
    "                img = ax.imshow(filter_img, cmap='gray', interpolation='nearest')\n",
    "            \n",
    "    plt.show()\n",
    "    \n",
    "    \n",
    "    \n",
    "# 指定したフィルタの時間変化(TH平面)　複数ver.mono\n",
    "def filter_singlemoves_THmono(filnums, filters, nx=filter_size_conv1, margin=0.1, scale=10):\n",
    "\n",
    "    FN, C, FT, FH, FW = filters.shape\n",
    "    ny = len(filnums)\n",
    "    \n",
    "    fig = plt.figure(figsize=(11,30))\n",
    "    #plt.title(\"x:width,y:height\",fontsize=10)\n",
    "    plt.axis(\"off\")\n",
    "    fig.subplots_adjust(left=0, right=0.9, bottom=0, top=1, hspace=0.05, wspace=0.05)\n",
    "    \n",
    "    for j in range(ny):\n",
    "        filter_choice = filters[filnums[j]-1,:,:,:,:].copy()\n",
    "        filter_choice = filter_choice.transpose(1,2,3,0) #(THWC)\n",
    "    \n",
    "    \n",
    "        for i in range(nx):\n",
    "            if i < nx:\n",
    "                all_filter_W = filters[:,:,:,:,i].copy()\n",
    "                all_filter_W = all_filter_W.transpose(0,2,3,1) #(NTHC)\n",
    "            \n",
    "                ax = fig.add_subplot(ny, nx, j*nx+i+1, xticks=[], yticks=[])\n",
    "                filter_img = filter_choice[:,:,i,:] #(THC)\n",
    "                filter_img = (filter_img - all_filter_W.min()) / (all_filter_W.max() - all_filter_W.min())  # 正規化\n",
    "                filter_img = (filter_img[:,:,0]+filter_img[:,:,1]+filter_img[:,:,2])/765\n",
    "                img = ax.imshow(filter_img, cmap='gray', interpolation='nearest')\n",
    "            \n",
    "    plt.show()\n",
    "\n",
    "# 指定したフィルタの時間変化(TW平面)　複数ver.mono\n",
    "def filter_singlemoves_TWmono(filnums, filters, nx=filter_size_conv1, margin=0.1, scale=10):\n",
    "\n",
    "    FN, C, FT, FH, FW = filters.shape\n",
    "    ny = len(filnums)\n",
    "    \n",
    "    fig = plt.figure(figsize=(11,30))\n",
    "    #plt.title(\"x:width,y:height\",fontsize=10)\n",
    "    plt.axis(\"off\")\n",
    "    fig.subplots_adjust(left=0, right=0.9, bottom=0, top=1, hspace=0.05, wspace=0.05)\n",
    "    \n",
    "    for j in range(ny):\n",
    "        filter_choice = filters[filnums[j]-1,:,:,:,:].copy()\n",
    "        filter_choice = filter_choice.transpose(1,3,2,0) #(TWHC)\n",
    "    \n",
    "    \n",
    "        for i in range(nx):\n",
    "            if i < nx:\n",
    "                all_filter_H = filters[:,:,:,i,:].copy()\n",
    "                all_filter_H = all_filter_H.transpose(0,2,3,1) #(NTWC)\n",
    "            \n",
    "                ax = fig.add_subplot(ny, nx, j*nx+i+1, xticks=[], yticks=[])\n",
    "                filter_img = filter_choice[:,:,i,:] #(TWC)\n",
    "                filter_img = (filter_img - all_filter_H.min()) / (all_filter_H.max() - all_filter_H.min())  # 正規化\n",
    "                filter_img = (filter_img[:,:,0]+filter_img[:,:,1]+filter_img[:,:,2])/765\n",
    "                img = ax.imshow(filter_img, cmap='gray', interpolation='nearest')\n",
    "            \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4d9a284-00bc-4459-87cb-9ddf3e1780f3",
   "metadata": {},
   "source": [
    "指定したフィルタのT変化(WH平面)、経路0、モノクロ版"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c214722",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "filter_singlemoves_WHmono(np.arange(1,num_channel+1),model.features0[0].conv.weight.detach().cpu().numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "198b9249-2e2b-43af-bafd-8d1acb86c026",
   "metadata": {},
   "source": [
    "指定したフィルタのT変化(WH平面)、経路0、モノクロ版"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70c0ed00-815a-4f70-9916-f2cfbdc2f241",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "filter_singlemoves_WHmono(np.arange(1,num_channel+1),model.features1[0].conv.weight.detach().cpu().numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1cde9ae-efdc-4bba-a39d-e2041332e15a",
   "metadata": {},
   "source": [
    "指定したフィルタのW変化(TH平面)、経路0、モノクロ版"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13ab1673",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "filter_singlemoves_THmono(np.arange(1,num_channel+1),model.features0[0].conv.weight.detach().cpu().numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "166c336d-9761-4992-91ef-c8ac814d2946",
   "metadata": {
    "tags": []
   },
   "source": [
    "指定したフィルタのW変化(TH平面)、経路1、モノクロ版"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46bc0d6c-be03-41fc-9a00-426c3f98d70e",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "filter_singlemoves_THmono(np.arange(1,num_channel+1),model.features1[0].conv.weight.detach().cpu().numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd0e635b-5f0b-472d-aa01-a06fef68aa50",
   "metadata": {},
   "source": [
    "指定したフィルタのH変化(TW平面)、経路0、モノクロ版"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09f2f20c",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "filter_singlemoves_TWmono(np.arange(1,num_channel+1),model.features0[0].conv.weight.detach().cpu().numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "598933a9-4e68-4e13-82fc-5eb4a3f50492",
   "metadata": {},
   "source": [
    "指定したフィルタのH変化(TW平面)、経路1、モノクロ版"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d88a8b7d-f98d-4ff5-88df-0866ffa5b50a",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "filter_singlemoves_TWmono(np.arange(1,num_channel+1),model.features1[0].conv.weight.detach().cpu().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "483f08e3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
